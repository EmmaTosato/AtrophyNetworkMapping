# ğŸ§  Deep Learning Pipeline - Overview

## ğŸ“Š Pipeline Workflow

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         FASE 1: HYPERPARAMETER TUNING                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                     â–¼
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚  Grid Search su combinazioni di:                 â”‚
        â”‚  â€¢ Model: ResNet3D, DenseNet3D, VGG16_3D        â”‚
        â”‚  â€¢ Optimizer: Adam, SGD                          â”‚
        â”‚  â€¢ Learning Rate: 1e-3, 1e-4, 1e-5             â”‚
        â”‚  â€¢ Batch Size: 4, 8, 16                         â”‚
        â”‚  â€¢ Weight Decay: 1e-4, 1e-3                     â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                     â–¼
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚  Per ogni configurazione:                        â”‚
        â”‚  1. 5-Fold Cross-Validation su train (105 pz)   â”‚
        â”‚  2. Salva best_model_fold{1-5}.pt               â”‚
        â”‚  3. Seleziona best fold (val accuracy)           â”‚
        â”‚  4. Test su test set (27 pz)                     â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                     â–¼
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚  Output:                                         â”‚
        â”‚  â€¢ grid_results.csv (tutte le config)            â”‚
        â”‚  â€¢ Seleziona migliori config (top accuracy)      â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    FASE 2: FINAL RUNS (Robustness Check)                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                     â–¼
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚  Usa i MIGLIORI hyperparameters dal tuning       â”‚
        â”‚  Ripeti con 5 seed diversi per robustezza:      â”‚
        â”‚  â€¢ Seed: 42, 123, 2023, 31415, 98765            â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                     â–¼
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚  Per ogni seed (run1-15):                        â”‚
        â”‚  1. 5-Fold Cross-Validation su train (105 pz)   â”‚
        â”‚  2. Salva best_model_fold{1-5}.pt               â”‚
        â”‚  3. Seleziona best fold (val accuracy)           â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                     â–¼
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚  Output:                                         â”‚
        â”‚  â€¢ all_training_results.csv                      â”‚
        â”‚  â€¢ best_model_fold{N}.pt per ogni run           â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                          FASE 3: FINAL TESTING                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                     â–¼
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚  Per ogni run:                                   â”‚
        â”‚  1. Carica best_model_fold{N}.pt                 â”‚
        â”‚  2. Testa su test set (27 pz)                    â”‚
        â”‚  3. Calcola metriche (acc, prec, rec, f1)        â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                     â–¼
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚  Output:                                         â”‚
        â”‚  â€¢ all_testing_results.csv                       â”‚
        â”‚  â€¢ Confusion matrices                            â”‚
        â”‚  â€¢ Performance report                            â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ”‘ Key Concepts

### 1ï¸âƒ£ **Data Splits** (Fissi per tutti gli esperimenti)
- **Train**: 105 pazienti (80%)
- **Test**: 27 pazienti (20%)
- File: `assets/split_cnn/{ADNI_PSP, ADNI_CBS, PSP_CBS}_splitted.csv`

### 2ï¸âƒ£ **Data Augmentation** (Solo in Training)
- **Train fold**: `FCmaps_augmented_processed/` (50Ã— augmented con HCP bootstrap)
- **Validation fold**: `FCmaps_processed/` (dati originali, no augmentation)
- **Test set**: `FCmaps_processed/` (dati originali, no augmentation)

### 3ï¸âƒ£ **Cross-Validation** (5-fold Stratified)
- Ogni fold: ~84 pazienti train, ~21 pazienti validation
- **Best fold**: Scelto in base a validation accuracy
- **Best epoch**: Early stopping su validation loss

### 4ï¸âƒ£ **Modelli Disponibili**
| Modello | Parametri | Batch Size Consigliato |
|---------|-----------|------------------------|
| ResNet3D | ~33M | 4, 16 |
| DenseNet3D | ~7M | 4, 16 |
| VGG16_3D | ~138M | 4, 8, 16 |

---

## ğŸ“‚ Struttura Output

```
results/
â”œâ”€â”€ tuning/
â”‚   â”œâ”€â”€ tuning{N}/
â”‚   â”‚   â”œâ”€â”€ config{M}/
â”‚   â”‚   â”‚   â”œâ”€â”€ best_model_fold{1-5}.pt
â”‚   â”‚   â”‚   â”œâ”€â”€ plots/
â”‚   â”‚   â”‚   â””â”€â”€ training_folds.xlsx
â”‚   â”‚   â””â”€â”€ grid_results.csv
â”‚   â”œâ”€â”€ merged_{GROUP}.csv      # Risultati test per tuning
â”‚   â””â”€â”€ summary.csv             # Riassunto tutti i tuning
â”‚
â””â”€â”€ runs/
    â”œâ”€â”€ run{N}/
    â”‚   â”œâ”€â”€ best_model_fold{1-5}.pt
    â”‚   â”œâ”€â”€ plots/
    â”‚   â”œâ”€â”€ training_folds.xlsx
    â”‚   â”œâ”€â”€ log_train{N}
    â”‚   â””â”€â”€ log_test{N}
    â”œâ”€â”€ all_training_results.csv
    â””â”€â”€ all_testing_results.csv
```

---

## ğŸ¯ Philosophy: Tuning vs Runs

### **Tuning** (Fase 1)
- **Obiettivo**: Trovare i migliori hyperparameters
- **Metodo**: Grid search + CV + Test
- **Output**: Selezione delle config migliori

### **Runs** (Fase 2-3)
- **Obiettivo**: Valutare stabilitÃ  e robustezza
- **Metodo**: CV con seed diversi + Test
- **Output**: Metriche finali con varianza

âš ï¸ **Nota**: L'accuracy del test set Ã¨ **bassa intenzionalmente** perchÃ©:
1. Dataset piccolo (105 train, 27 test)
2. Task difficile (discriminazione neurodegenerativa)
3. Focus su robustezza (varianza tra seed) non su performance assoluta

---

## ğŸ“ˆ Metriche Salvate

### Training (all_training_results.csv)
- `best_fold`: Fold selezionato
- `best_epoch`: Epoca di early stopping
- `best_accuracy`: Val accuracy del best fold
- `avg_accuracy`: Media val accuracy su tutti i fold
- Hyperparameters: model, lr, batch_size, optimizer, weight_decay

### Testing (all_testing_results.csv)
- `accuracy`: Accuracy su test set
- `precision`, `recall`, `f1`: Metriche dettagliate
- `seed`: Seed usato per il run

---

## ğŸš€ Quick Start

### 1. Hyperparameter Tuning
```bash
python src/DL_analysis/training/hyper_tuning.py
```

### 2. Final Runs
```bash
python src/DL_analysis/training/run_train.py
```

### 3. Final Testing
```bash
python src/DL_analysis/testing/run_test.py
```

---

## ğŸ“Š Confronto Gruppi

| Gruppo Pair | Train Size | Test Size | Tuning | Runs |
|-------------|------------|-----------|--------|------|
| ADNI vs PSP | 105 | 27 | tuning1-2 | run1-5 |
| ADNI vs CBS | 95 | 24 | tuning3 | run6-10 |
| PSP vs CBS | 80 | 20 | tuning4 | run11-15 |

---

## âš™ï¸ Configurazione

### File Principali
- `src/DL_analysis/config/cnn_config.json`: Config base (paths, hyperparams, flags)
- `src/DL_analysis/config/cnn_grid.json`: Grid search per tuning

### Flags Importanti
- `crossval_flag`: Abilita training con CV
- `evaluation_flag`: Abilita testing
- `tuning_flag`: ModalitÃ  tuning (ritorna risultati senza CSV)
- `plot`: Salva plot (learning curves, confusion matrices)
- `training_csv`: Salva metriche per-epoch in Excel

---

## ğŸ“ Note Tecniche

### Seed Management
- **Seed nel CV**: Controlla split dei fold (stratified split)
- **Seed in PyTorch**: Controlla weight initialization
- Nelle runs: seed diversi per testare robustezza

### Early Stopping
- Basato su **validation accuracy** (primary)
- Tiebreaker: **validation loss** (secondary)
- Best epoch puÃ² essere molto precoce (es. epoch 5)

### GPU Memory
- Batch size dipende da modello e GPU disponibile
- VGG16: Max 8, ResNet/DenseNet: Max 16
- Validation constraints in `is_valid_combo()`

---

**Autore**: Pipeline DL per classificazione neurodegenerativa  
**Ultima modifica**: Gennaio 2026
